{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "isolated-zoning",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/home/users1/musenips/master_venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "behind-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "import textwrap\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5TokenizerFast as T5Tokenizer\n",
    ")\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "outdoor-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "rcParams['figure.figsize'] = 16, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "buried-above",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e41d7c4-2642-465e-ab34-29be98953942",
   "metadata": {},
   "source": [
    "Commands for preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c13a8262-fdca-49a1-b1d8-ade71d88de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://gitlab.com/shimorina/webnlg-dataset.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "825680a2-76c2-4e41-a112-f6aed58623b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mv 'webnlg-dataset/release_v3.0/en' 'webnlg_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d0d7dfc-2364-4efd-bfea-53ff72a3090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -r --interactive=never 'webnlg-dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c43727-e442-4b4b-9873-9e48ae817d52",
   "metadata": {},
   "source": [
    "Commands for removing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a846b0ac-95dd-4de6-bb55-38c2260c1f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -r --interactive=never 'webnlg_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8689e820-475e-42ba-a36f-535401127ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm web*\\.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9a9a7cd-f301-4bfe-a309-93d9badb77a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "train_path = \"train/**/*\"\n",
    "dev_path = \"dev/**/*\"\n",
    "test_path = \"test/rdf-to-text-generation-test-data-with-refs-en\"\n",
    "sets = [train_path, dev_path, test_path]\n",
    "\n",
    "for s in sets:\n",
    "    files = glob.glob(os.getcwd() + \"/webnlg_data/\" + s + \".xml\", recursive=True)    \n",
    "    inputs = list()\n",
    "    outputs = list()\n",
    "    for file in files:\n",
    "        tree = ET.parse(file)\n",
    "        root = tree.getroot()    \n",
    "        for sub_root in root:\n",
    "            for entry in sub_root:\n",
    "                for element in entry:\n",
    "                    if \"modifiedtripleset\" in str(element):\n",
    "                        inp = \" && \".join([triple.text for triple in element])\n",
    "                        # inp = \" && \".join([\"|\".join([e.strip(\"\\\"\") for e in triple.text.split(\"|\")]) for triple in element])\n",
    "                    if \"lex\" in str(element):\n",
    "                        out = element.text\n",
    "                        inputs.append(inp)\n",
    "                        outputs.append(out)\n",
    "\n",
    "    mdata_dct={\"input_text\":[], \"target_text\":[]}\n",
    "    for i, _ in enumerate(inputs):\n",
    "        mdata_dct['input_text'].append(inputs[i])\n",
    "        mdata_dct['target_text'].append(outputs[i])\n",
    "\n",
    "\n",
    "    df=pd.DataFrame(mdata_dct)\n",
    "    df.to_csv('webNLG2020_' + s.split(\"/\")[0] + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13329b76-9ffc-487d-913b-ca46769b4276",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'webNLG2020_train.csv'\n",
    "DEV_PATH = 'webNLG2020_dev.csv'\n",
    "TEST_PATH = 'webNLG2020_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "naval-adult",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "dev_df = pd.read_csv(DEV_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a5e26ae-d246-4f45-b383-9bfbc2a96a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AmeriGas | country | United_States &amp;&amp; AmeriGas...</td>\n",
       "      <td>AmeriGas was founded in the United States on 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AmeriGas | country | United_States &amp;&amp; AmeriGas...</td>\n",
       "      <td>AmeriGas, founded on 01-01-1959, works in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AmeriGas | country | United_States &amp;&amp; AmeriGas...</td>\n",
       "      <td>AmeriGas, whose home country is the United Sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AmeriGas | country | United_States &amp;&amp; AmeriGas...</td>\n",
       "      <td>AmeriGas is based in the United States and emp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AmeriGas | country | United_States &amp;&amp; AmeriGas...</td>\n",
       "      <td>AmeriGas, whose current employment is 8,500, h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  \\\n",
       "0  AmeriGas | country | United_States && AmeriGas...   \n",
       "1  AmeriGas | country | United_States && AmeriGas...   \n",
       "2  AmeriGas | country | United_States && AmeriGas...   \n",
       "3  AmeriGas | country | United_States && AmeriGas...   \n",
       "4  AmeriGas | country | United_States && AmeriGas...   \n",
       "\n",
       "                                         target_text  \n",
       "0  AmeriGas was founded in the United States on 1...  \n",
       "1  AmeriGas, founded on 01-01-1959, works in the ...  \n",
       "2  AmeriGas, whose home country is the United Sta...  \n",
       "3  AmeriGas is based in the United States and emp...  \n",
       "4  AmeriGas, whose current employment is 8,500, h...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = pd.concat([train_df, dev_df, test_df])\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4abd7a96-67a2-4c15-b95e-bd5aa8184401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35426, 2) (4464, 2) (5150, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, dev_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6b46bf4-c609-4495-b3ce-472bf5461d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"t5-small\"\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "376cd62a-c628-4be1-9906-bdffb3980e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_lens = list()\n",
    "summary_lens = list()\n",
    "for idx, row in full_data.iterrows():\n",
    "    rdf_encoding = tokenizer(row[\"input_text\"])\n",
    "    rdf_lens.append(len(rdf_encoding.tokens()))\n",
    "    summary_encoding = tokenizer(row[\"target_text\"])\n",
    "    summary_lens.append(len(summary_encoding.tokens()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64244a3a-6005-4f55-94f6-a211f7ef39dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(max(rdf_lens),max(summary_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fa4e221-a887-40b0-a7b4-494082ce379c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/users1/musenips/.netrc\n"
     ]
    }
   ],
   "source": [
    "!wandb login '47616056d2ebbf7dea86db60a5fc58145cd234fc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "contemporary-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebNLGDataset(Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        tokenizer: T5Tokenizer,\n",
    "        text_max_token_len: int = 263,\n",
    "        summary_max_token_len: int = 147\n",
    "    ):\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.text_max_token_len = text_max_token_len\n",
    "        self.summary_max_token_len = summary_max_token_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        data_row = self.data.iloc[index]\n",
    "        \n",
    "        text = data_row['input_text']\n",
    "        \n",
    "        text_encoding = tokenizer(\n",
    "            text,\n",
    "            max_length=self.text_max_token_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        summary_encoding = tokenizer(\n",
    "            data_row[\"target_text\"],\n",
    "            max_length=self.text_max_token_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        labels = summary_encoding[\"input_ids\"]\n",
    "        labels[labels == 0] = -100\n",
    "        \n",
    "        return dict(\n",
    "            text=text,\n",
    "            summary=data_row[\"target_text\"],\n",
    "            text_input_ids=text_encoding[\"input_ids\"].flatten(),\n",
    "            text_attention_mask=text_encoding[\"attention_mask\"].flatten(),\n",
    "            labels=labels.flatten(),\n",
    "            labels_attention_mask=summary_encoding[\"attention_mask\"].flatten()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "subsequent-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebNLGDataModule(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        train_df: pd.DataFrame,\n",
    "        dev_df: pd.DataFrame,\n",
    "        test_df: pd.DataFrame,\n",
    "        tokenizer: T5Tokenizer,\n",
    "        batch_size: int = 8,\n",
    "        text_max_token_len: int = 263,\n",
    "        summary_max_token_len: int = 147\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.train_df = train_df\n",
    "        self.dev_df = dev_df\n",
    "        self.test_df = test_df\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text_max_token_len = text_max_token_len\n",
    "        self.summary_max_token_len = summary_max_token_len\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = WebNLGDataset(\n",
    "            self.train_df,\n",
    "            self.tokenizer,\n",
    "            self.text_max_token_len,\n",
    "            self.summary_max_token_len\n",
    "        )\n",
    "        self.test_dataset = WebNLGDataset(\n",
    "            self.test_df,\n",
    "            self.tokenizer,\n",
    "            self.text_max_token_len,\n",
    "            self.summary_max_token_len\n",
    "        )\n",
    "        self.dev_dataset = WebNLGDataset(\n",
    "            self.dev_df,\n",
    "            self.tokenizer,\n",
    "            self.text_max_token_len,\n",
    "            self.summary_max_token_len\n",
    "        )\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=56\n",
    "        )\n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.dev_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=56\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=56\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "roman-resident",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 3\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "\n",
    "data_module = WebNLGDataModule(train_df, test_df, dev_df, tokenizer, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "color-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebNLGModel(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict=True)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, decoder_attention_mask, labels=None):\n",
    "        \n",
    "        output = self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels,\n",
    "            decoder_attention_mask=decoder_attention_mask\n",
    "        )\n",
    "        \n",
    "        return output.loss, output.logits\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"text_input_ids\"]\n",
    "        attention_mask = batch[\"text_attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        labels_attention_mask = batch[\"labels_attention_mask\"]\n",
    "        \n",
    "        loss, outputs = self(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_attention_mask=labels_attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"text_input_ids\"]\n",
    "        attention_mask = batch[\"text_attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        labels_attention_mask = batch[\"labels_attention_mask\"]\n",
    "        \n",
    "        loss, outputs = self(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_attention_mask=labels_attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"text_input_ids\"]\n",
    "        attention_mask = batch[\"text_attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        labels_attention_mask = batch[\"labels_attention_mask\"]\n",
    "        \n",
    "        loss, outputs = self(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_attention_mask=labels_attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return AdamW(self.parameters(), lr=0.0001)         ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "surgical-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WebNLGModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "individual-advance",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users1/musenips/.local/lib/python3.10/site-packages/pytorch_lightning/utilities/distributed.py:52: UserWarning: Checkpoint directory checkpoints exists and is not empty.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "logger = WandbLogger('WebNLG')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    max_epochs=N_EPOCHS,\n",
    "    gpus=1,                                     ###############\n",
    "    progress_bar_refresh_rate=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "induced-tuesday",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpavl_os\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/users1/musenips/wandb/run-20220714_215410-1hpmaxgj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/pavl_os/uncategorized/runs/1hpmaxgj\" target=\"_blank\">WebNLG</a></strong> to <a href=\"https://wandb.ai/pavl_os/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 60.5 M\n",
      "-----------------------------------------------------\n",
      "60.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 M    Total params\n",
      "242.026   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71532fc575f4f4da7ac1d1b9bed2a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "337df02e68c24c2882979b59487b4b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe082fd06a6431abdb3d560c7acc17b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 4428: val_loss reached 1.34659 (best 1.34659), saving model to \"/home/users1/musenips/checkpoints/best-checkpoint-v1.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418e27935a4d43ffbdc47dfdcae8644f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 8857: val_loss reached 1.30416 (best 1.30416), saving model to \"/home/users1/musenips/checkpoints/best-checkpoint-v1.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a708428915a74abd9f83216fd4210d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 13286: val_loss reached 1.28989 (best 1.28989), saving model to \"/home/users1/musenips/checkpoints/best-checkpoint-v1.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9a02dd3-d816-43d7-8ebc-70873551c4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = WebNLGModel.load_from_checkpoint(\n",
    "   trainer.checkpoint_callback.best_model_path\n",
    ")\n",
    "\n",
    "trained_model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba24b571-499f-42ae-8eb1-ec1626a1ed7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/users1/musenips/checkpoints/best-checkpoint-v1.ckpt'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "109c79ce-f296-4252-ba00-ccbe478fff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text):\n",
    "    text_encoding = tokenizer(\n",
    "        text,\n",
    "        max_length=263,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        add_special_tokens=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    generated_ids = trained_model.model.generate(\n",
    "        input_ids=text_encoding[\"input_ids\"],\n",
    "        attention_mask=text_encoding[\"attention_mask\"],\n",
    "        max_length=147,\n",
    "        num_beams=2,\n",
    "        repetition_penalty=2.5,\n",
    "        length_penalty=1.0,\n",
    "        early_stopping=True\n",
    "    )\n",
    "        \n",
    "    preds = [\n",
    "        tokenizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        for gen_id in generated_ids\n",
    "    ]\n",
    "        \n",
    "    return \"\".join(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e07372a6-2195-4e48-ae15-417e2a8db200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users1/musenips/.local/lib/python3.10/site-packages/transformers/generation_utils.py:1777: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  next_indices = next_tokens // vocab_size\n"
     ]
    }
   ],
   "source": [
    "sample_row = test_df.iloc[0]\n",
    "text = sample_row[\"input_text\"]\n",
    "model_summary = summarize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81122da3-6f94-48bc-b6c3-9cc5d2cb5b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Estádio_Municipal_Coaracy_da_Mata_Fonseca | location | Arapiraca && Agremiação_Sportiva_Arapiraquense | league | Campeonato_Brasileiro_Série_C && Campeonato_Brasileiro_Série_C | country | Brazil && Agremiação_Sportiva_Arapiraquense | nickname | \"\\'\\'Alvinegro\" && Agremiação_Sportiva_Arapiraquense | ground | Estádio_Municipal_Coaracy_da_Mata_Fonseca'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c777fc85-3eaf-4e52-a186-09a454d3570f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Estádio Municipal Coaracy da Mata Fonseca is the name of the ground of Agremiação Sportiva Arapiraquense in Arapiraca. Agremiação Sportiva Arapiraquense, nicknamed \"Alvinegro\", lay in the Campeonato Brasileiro Série C league from Brazil.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_row[\"target_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b798066-68ad-4b2d-ae76-e67c2636155e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Agremiaço Sportiva Arapiraquense's ground is the Estádio Municipal Coaracy da Mata Fonseca, located in Arapiraca, Brazil. The nickname of the club is Alvinegro and they play in the Campeonato Brasileiro Série C league in Brazil.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64c02ae7-9456-4b74-9f7b-aaf118ee3e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_row = test_df.iloc[2]\n",
    "text = sample_row[\"input_text\"]\n",
    "model_summary = summarize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c65a53d2-78d4-4563-a9b9-e97ad506f23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nie_Haisheng | birthDate | 1964-10-13 && Nie_Haisheng | occupation | Fighter_pilot'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9938134-0fe5-4699-9ccb-a1814ed802cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nie Haisheng, born on October 13, 1964, worked as a fighter pilot.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_row[\"target_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8f5e04f-05e0-4e24-92c1-705da37e59fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nie Haisheng was born on 13 October 1964 and served as a fighter pilot.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5159afd-dafe-4631-b8e6-7a2d38c4af05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
