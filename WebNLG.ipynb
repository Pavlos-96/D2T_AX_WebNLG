{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "isolated-zoning",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install transformers==4.5.0\n",
    "# !pip install pytorch-lightning==1.2.7\n",
    "# !pip install seaborn\n",
    "# !pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47145252-d196-4218-82c0-ca3a13246293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e740e92-9512-4688-8335-114cb2d7bb53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "behind-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "import textwrap\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5TokenizerFast as T5Tokenizer\n",
    ")\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "outdoor-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "rcParams['figure.figsize'] = 16, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "buried-above",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c13a8262-fdca-49a1-b1d8-ade71d88de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://gitlab.com/shimorina/webnlg-dataset.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "825680a2-76c2-4e41-a112-f6aed58623b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mv 'webnlg-ataset/release_v3.0/en' 'webnlg_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9a9a7cd-f301-4bfe-a309-93d9badb77a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "train_path = \"train/**/*\"\n",
    "dev_path = \"dev/**/*\"\n",
    "test_path = \"test/rdf-to-text-generation-test-data-with-refs-en\"\n",
    "sets = [train_path, dev_path, test_path]\n",
    "\n",
    "for s in sets:\n",
    "    files = glob.glob(os.getcwd() + \"/webnlg_data/\" + s + \".xml\", recursive=True)    \n",
    "    inputs = list()\n",
    "    outputs = list()\n",
    "    for file in files:\n",
    "        tree = ET.parse(file)\n",
    "        root = tree.getroot()    \n",
    "        for sub_root in root:\n",
    "            for entry in sub_root:\n",
    "                for element in entry:\n",
    "                    if \"modifiedtripleset\" in str(element):\n",
    "                        inp = \" && \".join([triple.text for triple in element])\n",
    "                        # inp = \" && \".join([\"|\".join([e.strip(\"\\\"\") for e in triple.text.split(\"|\")]) for triple in element])\n",
    "                    if \"lex\" in str(element):\n",
    "                        out = element.text\n",
    "                        inputs.append(inp)\n",
    "                        outputs.append(out)\n",
    "\n",
    "    mdata_dct={\"input_text\":[], \"target_text\":[]}\n",
    "    for i, _ in enumerate(inputs):\n",
    "        mdata_dct['input_text'].append(inputs[i])\n",
    "        mdata_dct['target_text'].append(outputs[i])\n",
    "\n",
    "\n",
    "    df=pd.DataFrame(mdata_dct)\n",
    "    df.to_csv('webNLG2020_' + s.split(\"/\")[0] + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13329b76-9ffc-487d-913b-ca46769b4276",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'webNLG2020_train.csv'\n",
    "DEV_PATH = 'webNLG2020_dev.csv'\n",
    "TEST_PATH = 'webNLG2020_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "naval-adult",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "dev_df = pd.read_csv(DEV_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a5e26ae-d246-4f45-b383-9bfbc2a96a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aarhus_Airport | cityServed | \"Aarhus, Denmark\"</td>\n",
       "      <td>The Aarhus is the airport of Aarhus, Denmark.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aarhus_Airport | cityServed | \"Aarhus, Denmark\"</td>\n",
       "      <td>Aarhus Airport serves the city of Aarhus, Denm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aarhus_Airport | cityServed | Aarhus</td>\n",
       "      <td>Aarhus airport serves the city of Aarhus.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aarhus_Airport | elevationAboveTheSeaLevel | 25.0</td>\n",
       "      <td>Aarhus Airport is 25 metres above sea level.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aarhus_Airport | elevationAboveTheSeaLevel | 25.0</td>\n",
       "      <td>Aarhus airport is at an elevation of 25 metres...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  \\\n",
       "0    Aarhus_Airport | cityServed | \"Aarhus, Denmark\"   \n",
       "1    Aarhus_Airport | cityServed | \"Aarhus, Denmark\"   \n",
       "2               Aarhus_Airport | cityServed | Aarhus   \n",
       "3  Aarhus_Airport | elevationAboveTheSeaLevel | 25.0   \n",
       "4  Aarhus_Airport | elevationAboveTheSeaLevel | 25.0   \n",
       "\n",
       "                                         target_text  \n",
       "0      The Aarhus is the airport of Aarhus, Denmark.  \n",
       "1  Aarhus Airport serves the city of Aarhus, Denm...  \n",
       "2          Aarhus airport serves the city of Aarhus.  \n",
       "3       Aarhus Airport is 25 metres above sea level.  \n",
       "4  Aarhus airport is at an elevation of 25 metres...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = pd.concat([train_df, dev_df, test_df])\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4abd7a96-67a2-4c15-b95e-bd5aa8184401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35426, 2) (4464, 2) (5150, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, dev_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6b46bf4-c609-4495-b3ce-472bf5461d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"t5-small\"\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "376cd62a-c628-4be1-9906-bdffb3980e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf_lens = list()\n",
    "summary_lens = list()\n",
    "for idx, row in full_data.iterrows():\n",
    "    rdf_encoding = tokenizer(row[\"input_text\"])\n",
    "    rdf_lens.append(len(rdf_encoding.tokens()))\n",
    "    summary_encoding = tokenizer(row[\"target_text\"])\n",
    "    summary_lens.append(len(summary_encoding.tokens()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64244a3a-6005-4f55-94f6-a211f7ef39dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263 147\n"
     ]
    }
   ],
   "source": [
    "print(max(rdf_lens),max(summary_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fa4e221-a887-40b0-a7b4-494082ce379c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/studio-lab-user/.netrc\n"
     ]
    }
   ],
   "source": [
    "!wandb login '47616056d2ebbf7dea86db60a5fc58145cd234fc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "contemporary-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebNLGDataset(Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        tokenizer: T5Tokenizer,\n",
    "        text_max_token_len: int = 263,\n",
    "        summary_max_token_len: int = 147\n",
    "    ):\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.text_max_token_len = text_max_token_len\n",
    "        self.summary_max_token_len = summary_max_token_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        data_row = self.data.iloc[index]\n",
    "        \n",
    "        text = data_row['input_text']\n",
    "        \n",
    "        text_encoding = tokenizer(\n",
    "            text,\n",
    "            max_length=self.text_max_token_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        summary_encoding = tokenizer(\n",
    "            data_row[\"target_text\"],\n",
    "            max_length=self.text_max_token_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        labels = summary_encoding[\"input_ids\"]\n",
    "        labels[labels == 0] = -100\n",
    "        \n",
    "        return dict(\n",
    "            text=text,\n",
    "            summary=data_row[\"target_text\"],\n",
    "            text_input_ids=text_encoding[\"input_ids\"].flatten(),\n",
    "            text_attention_mask=text_encoding[\"attention_mask\"].flatten(),\n",
    "            labels=labels.flatten(),\n",
    "            labels_attention_mask=summary_encoding[\"attention_mask\"].flatten()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "subsequent-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebNLGDataModule(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        train_df: pd.DataFrame,\n",
    "        dev_df: pd.DataFrame,\n",
    "        test_df: pd.DataFrame,\n",
    "        tokenizer: T5Tokenizer,\n",
    "        batch_size: int = 8,\n",
    "        text_max_token_len: int = 263,\n",
    "        summary_max_token_len: int = 147\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.train_df = train_df\n",
    "        self.dev_df = dev_df\n",
    "        self.test_df = test_df\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text_max_token_len = text_max_token_len\n",
    "        self.summary_max_token_len = summary_max_token_len\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = WebNLGDataset(\n",
    "            self.train_df,\n",
    "            self.tokenizer,\n",
    "            self.text_max_token_len,\n",
    "            self.summary_max_token_len\n",
    "        )\n",
    "        self.test_dataset = WebNLGDataset(\n",
    "            self.test_df,\n",
    "            self.tokenizer,\n",
    "            self.text_max_token_len,\n",
    "            self.summary_max_token_len\n",
    "        )\n",
    "        self.dev_dataset = WebNLGDataset(\n",
    "            self.dev_df,\n",
    "            self.tokenizer,\n",
    "            self.text_max_token_len,\n",
    "            self.summary_max_token_len\n",
    "        )\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=2\n",
    "        )\n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.dev_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=2\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=2\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "roman-resident",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 3\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "\n",
    "data_module = WebNLGDataModule(train_df, test_df, dev_df, tokenizer, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "color-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebNLGModel(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict=True)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, decoder_attention_mask, labels=None):\n",
    "        \n",
    "        output = self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels,\n",
    "            decoder_attention_mask=decoder_attention_mask\n",
    "        )\n",
    "        \n",
    "        return output.loss, output.logits\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"text_input_ids\"]\n",
    "        attention_mask = batch[\"text_attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        labels_attention_mask = batch[\"labels_attention_mask\"]\n",
    "        \n",
    "        loss, outputs = self(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_attention_mask=labels_attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"text_input_ids\"]\n",
    "        attention_mask = batch[\"text_attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        labels_attention_mask = batch[\"labels_attention_mask\"]\n",
    "        \n",
    "        loss, outputs = self(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_attention_mask=labels_attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"text_input_ids\"]\n",
    "        attention_mask = batch[\"text_attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        labels_attention_mask = batch[\"labels_attention_mask\"]\n",
    "        \n",
    "        loss, outputs = self(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_attention_mask=labels_attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return AdamW(self.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "surgical-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WebNLGModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "individual-advance",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "logger = WandbLogger()\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "    max_epochs=N_EPOCHS,\n",
    "    gpus=1,                                     ###############\n",
    "    progress_bar_refresh_rate=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-tuesday",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpavl_os\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/studio-lab-user/sagemaker-studiolab-notebooks/wandb/run-20220706_194659-2m1v9qva</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/pavl_os/uncategorized/runs/2m1v9qva\" target=\"_blank\">fast-sun-7</a></strong> to <a href=\"https://wandb.ai/pavl_os/uncategorized\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 60.5 M\n",
      "-----------------------------------------------------\n",
      "60.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 M    Total params\n",
      "242.026   Total estimated model params size (MB)\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:52: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d24355c7ba8454a94dadbc7b6713abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:52: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faea6c9f26a640efa8b57a47b2479689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 4428: val_loss reached 1.34267 (best 1.34267), saving model to \"/home/studio-lab-user/sagemaker-studiolab-notebooks/checkpoints/best-checkpoint-v6.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 8857: val_loss reached 1.31121 (best 1.31121), saving model to \"/home/studio-lab-user/sagemaker-studiolab-notebooks/checkpoints/best-checkpoint-v6.ckpt\" as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9adb3edae6c41929924c2fac5c7a785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9a02dd3-d816-43d7-8ebc-70873551c4e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/home/studio-lab-user/sagemaker-studiolab-notebooks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_74/775226356.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m trained_model = WebNLGModel.load_from_checkpoint(\n\u001b[0m\u001b[1;32m      2\u001b[0m    \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_model_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/pytorch_lightning/core/saving.py\u001b[0m in \u001b[0;36mload_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhparams_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/pytorch_lightning/utilities/cloud_io.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path_or_url, map_location)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict_from_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_filesystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/fsspec/spec.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m             \u001b[0mac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"autocommit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m             f = self._open(\n\u001b[0m\u001b[1;32m   1038\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/fsspec/implementations/local.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_mkdir\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mLocalFileOpener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtouch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/fsspec/implementations/local.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_compression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocksize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/fsspec/implementations/local.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocommit\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                     \u001b[0mcompress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/home/studio-lab-user/sagemaker-studiolab-notebooks'"
     ]
    }
   ],
   "source": [
    "trained_model = WebNLGModel.load_from_checkpoint(\n",
    "   trainer.checkpoint_callback.best_model_path\n",
    ")\n",
    "\n",
    "trained_model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba24b571-499f-42ae-8eb1-ec1626a1ed7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/studio-lab-user/sagemaker-studiolab-notebooks/checkpoints/best-checkpoint-v3.ckpt'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "109c79ce-f296-4252-ba00-ccbe478fff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(text):\n",
    "    text_encoding = tokenizer(\n",
    "        text,\n",
    "        max_length=263,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        add_special_tokens=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    generated_ids = trained_model.model.generate(\n",
    "        input_ids=text_encoding[\"input_ids\"],\n",
    "        attention_mask=text_encoding[\"attention_mask\"],\n",
    "        max_length=147,\n",
    "        num_beams=2,\n",
    "        repetition_penalty=2.5,\n",
    "        length_penalty=1.0,\n",
    "        early_stopping=True\n",
    "    )\n",
    "        \n",
    "    preds = [\n",
    "        tokenizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        for gen_id in generated_ids\n",
    "    ]\n",
    "        \n",
    "    return \"\".join(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e07372a6-2195-4e48-ae15-417e2a8db200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/generation_utils.py:1777: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  next_indices = next_tokens // vocab_size\n"
     ]
    }
   ],
   "source": [
    "sample_row = test_df.iloc[0]\n",
    "text = sample_row[\"input_text\"]\n",
    "model_summary = summarize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81122da3-6f94-48bc-b6c3-9cc5d2cb5b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EstÃ¡dio_Municipal_Coaracy_da_Mata_Fonseca | location | Arapiraca && AgremiaÃ§Ã£o_Sportiva_Arapiraquense | league | Campeonato_Brasileiro_SÃ©rie_C && Campeonato_Brasileiro_SÃ©rie_C | country | Brazil && AgremiaÃ§Ã£o_Sportiva_Arapiraquense | nickname | \"\\'\\'Alvinegro\" && AgremiaÃ§Ã£o_Sportiva_Arapiraquense | ground | EstÃ¡dio_Municipal_Coaracy_da_Mata_Fonseca'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c777fc85-3eaf-4e52-a186-09a454d3570f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EstÃ¡dio Municipal Coaracy da Mata Fonseca is the name of the ground of AgremiaÃ§Ã£o Sportiva Arapiraquense in Arapiraca. AgremiaÃ§Ã£o Sportiva Arapiraquense, nicknamed \"Alvinegro\", lay in the Campeonato Brasileiro SÃ©rie C league from Brazil.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_row[\"target_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b798066-68ad-4b2d-ae76-e67c2636155e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Estdio_Municipal_Coaracy_da_Mata_Fonseca | location | Arapiraca && Agremia£o_Sportiva_Arapiraquense | league | Campeonato_Brasileiro_Srie_C && Campeonato_Brasileiro_Srie_C | country | Brazil && Agremia£o_Sportiva_Arapira'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64c02ae7-9456-4b74-9f7b-aaf118ee3e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_row = test_df.iloc[2]\n",
    "text = sample_row[\"input_text\"]\n",
    "model_summary = summarize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c65a53d2-78d4-4563-a9b9-e97ad506f23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nie_Haisheng | birthDate | 1964-10-13 && Nie_Haisheng | occupation | Fighter_pilot'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9938134-0fe5-4699-9ccb-a1814ed802cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nie Haisheng, born on October 13, 1964, worked as a fighter pilot.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_row[\"target_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8f5e04f-05e0-4e24-92c1-705da37e59fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nie_Haisheng | birthDate | 1964-10-13 && Nie_Haisheng | occupation | Fighter_pilot'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
